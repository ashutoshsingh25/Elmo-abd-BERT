{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the training and testing data\n",
    "faq_train = pd.read_excel(\"faq.xlsx\")\n",
    "faq_test = pd.read_excel(\"faq_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (12500, 2)\n",
      "Testing data shape:  (424, 2)\n"
     ]
    }
   ],
   "source": [
    "#Find dimensions of data\n",
    "print(\"Training data shape: \", faq_train.shape)\n",
    "print(\"Testing data shape: \", faq_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Data\n",
      "                                      Question Title  Remarks\n",
      "0  I have one chanakya  since 1860-2010 income ta...      FAQ\n",
      "1                                             325000  Not FAQ\n",
      "2                                         Back cover  Not FAQ\n",
      "3  à¤à¥à¤¯à¤¾ pulverizer à¤®à¤¶à¥à¤¨ à¤¸à¥ à¤...      FAQ\n",
      "4                                         Ikkat silk  Not FAQ\n",
      "Testing data\n",
      "                                      Question Title  Remarks\n",
      "0  I want to Armature for philips food processor ...  Not FAQ\n",
      "1                     Minimum how many KGS purchased  Not FAQ\n",
      "2                     Minimum how many KGS purchased  Not FAQ\n",
      "3                                        baby rabbit  Not FAQ\n",
      "4    I am 6 foot 2 and I want a metal bed. Possible?  Not FAQ\n"
     ]
    }
   ],
   "source": [
    "#Displaying head of datasets\n",
    "print(\"Traning Data\")\n",
    "print(faq_train.head())\n",
    "print(\"Testing data\")\n",
    "print(faq_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess/clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Remove numbers\n",
    "faq_train['cleanQT'] = faq_train['Question Title'].str.replace(\"[0-9]\",\" \")\n",
    "faq_test['cleanQT'] = faq_test['Question Title'].str.replace(\"[0-9]\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Remove special symbols\n",
    "special_symbols = '!@#$%^&*()_-+=[]\\{}|;\",.<>/?~:\\\"'\n",
    "faq_train['cleanQT'] = faq_train['cleanQT'].apply(lambda rss: ''.join(ch for ch in rss if ch not in set(special_symbols)))\n",
    "faq_test['cleanQT'] = faq_test['cleanQT'].apply(lambda rss: ''.join(ch for ch in rss if ch not in set(special_symbols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Convert all characters to lowercase\n",
    "faq_train['cleanQT'] = faq_train['cleanQT'].str.lower()\n",
    "faq_test['cleanQT'] = faq_test['cleanQT'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Remove white spaces\n",
    "faq_test['cleanQT'] = faq_test['cleanQT'].apply(lambda rws: ' '.join(rws.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "                                          Question Title  Remarks  \\\n",
      "12247          What is Electro Mechanical Contact Coder?      FAQ   \n",
      "1402                                         jcb  bh16sp  Not FAQ   \n",
      "9593   What is the price of electrical circuit breake...      FAQ   \n",
      "506            Looking Fruit Juice Manufacturer or Plant  Not FAQ   \n",
      "1608        What is the best price of Fragrance Perfume?      FAQ   \n",
      "\n",
      "                                                 cleanQT  \n",
      "12247           what is electro mechanical contact coder  \n",
      "1402                                         jcb  bh  sp  \n",
      "9593   what is the price of electrical circuit breake...  \n",
      "506            looking fruit juice manufacturer or plant  \n",
      "1608         what is the best price of fragrance perfume  \n",
      "Testing data\n",
      "                                     Question Title  Remarks  \\\n",
      "100  5 inch kitchan west coupling will be availabal  Not FAQ   \n",
      "226                        goldikapasbijbhav janavo  Not FAQ   \n",
      "215        Dealer in sonebhadra give no and address  Not FAQ   \n",
      "227                     metal shelf brackets rajkot  Not FAQ   \n",
      "314                                     Mere pas ha  Not FAQ   \n",
      "\n",
      "                                          cleanQT  \n",
      "100  inch kitchan west coupling will be availabal  \n",
      "226                      goldikapasbijbhav janavo  \n",
      "215      dealer in sonebhadra give no and address  \n",
      "227                   metal shelf brackets rajkot  \n",
      "314                                   mere pas ha  \n"
     ]
    }
   ],
   "source": [
    "#Analyzing differences before/after preprocessing data\n",
    "print(\"Training data\")\n",
    "print(faq_train.sample(5))\n",
    "print(\"Testing data\")\n",
    "print(faq_test.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing ELMo vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries for ELMo\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0605 11:06:41.314031  4844 deprecation.py:323] From C:\\Users\\Imart\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Loading the ELMo module\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function for creating ELMo vectors\n",
    "def elmo_vectors(text):\n",
    "    embeddings = elmo(text.tolist(),signature = \"default\", as_dict = True)[\"elmo\"]\n",
    "    with tf.compat.v1.Session() as session:\n",
    "        session.run(tf.compat.v1.global_variables_initializer())\n",
    "        session.run(tf.compat.v1.tables_initializer())\n",
    "        return session.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset into batches for better computation\n",
    "elmo_start_time = time.time()\n",
    "faq_train_list = [faq_train[i:i+100] for i in range(0,faq_train.shape[0],100)]\n",
    "faq_test_list = [faq_test[i:i+100] for i in range(0,faq_test.shape[0],100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting ELMo vectors\n",
    "elmo_extraction_start_time = time.time()\n",
    "faq_elmo_train = [elmo_vectors(x['cleanQT']) for x in faq_train_list]\n",
    "faq_elmo_test = [elmo_vectors(x['cleanQT']) for x in faq_test_list]\n",
    "elmo_extraction_end_time = time.time()\n",
    "print(\"Total extraction time for ELMo vectors: {} seconds\".format(elmo_extraction_end_time - elmo_extraction_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking dimensions of ELMo vectors\n",
    "print(\"Training: \",len(faq_elmo_train))\n",
    "print(\"Testing: \",len(faq_elmo_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenatening all batches\n",
    "elmo_concat_start_time = time.time()\n",
    "elmo_faq_train = np.concatenate(faq_elmo_train, axis = 0)\n",
    "elmo_faq_test = np.concatenate(faq_elmo_test, axis = 0)\n",
    "elmo_end_time = elmo_concat_end_time = time.time()\n",
    "print(\"Total concatenation time: {} seconds\".format(elmo_concat_end_time - elmo_concat_start_time))\n",
    "print(\"Total time for ELMo vector extraction: {} seconds\".format(elmo_end_time - elmo_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving output to pickle file\n",
    "pickle_out_train = open(\"elmo_faq_train_04062019.pickle\",\"wb\")\n",
    "pickle_out_test = open(\"elmo_faq_test_04062019.pickle\",\"wb\")\n",
    "pickle.dump(elmo_faq_train, pickle_out_train)\n",
    "pickle.dump(elmo_faq_test,pickle_out_test)\n",
    "pickle_out_train.close()\n",
    "pickle_out_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading ELMo vectors pickle file\n",
    "pickle_in_train = open(\"elmo_faq_train_04062019.pickle\",\"rb\")\n",
    "pickle_in_test = open(\"elmo_faq_test_04062019.pickle\",\"rb\")\n",
    "elmo_faq_train = pickle.load(pickle_in_train)\n",
    "elmo_faq_test = pickle.load(pickle_in_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (12500, 1024)\n",
      "Testing:  (424, 1024)\n"
     ]
    }
   ],
   "source": [
    "#Checking shape of concatenated files\n",
    "print(\"Training: \",elmo_faq_train.shape)\n",
    "print(\"Testing: \",elmo_faq_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining training and validation sets\n",
    "xtrain = pd.DataFrame(elmo_faq_train)\n",
    "ytrain = faq_train['Remarks']\n",
    "xvalid = pd.DataFrame(elmo_faq_test)\n",
    "yvalid = faq_test['Remarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Buidling a logistic Regression Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "lr_start_time = time.time()\n",
    "regressor = LogisticRegression()\n",
    "regressor.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent on LR: 3.3331825733184814 seconds\n"
     ]
    }
   ],
   "source": [
    "#Predicting on the validation set\n",
    "pred_val_lr = regressor.predict(xvalid)\n",
    "lr_end_time = time.time()\n",
    "print(\"Total time spent on LR: {} seconds\".format(lr_end_time - lr_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Precision:  0.8173913043478261\n",
      "Recall:  0.7899159663865546\n",
      "F1 Score:  0.8034188034188035\n",
      "MCC:  0.7287335379525473\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of Logistic Regression model\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_lr,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_lr,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_lr,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building a Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_start_time = time.time()\n",
    "nbclassifier = GaussianNB()\n",
    "nbclassifier.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent on NB: 0.8977758884429932 seconds\n"
     ]
    }
   ],
   "source": [
    "#Predicting on the validation set\n",
    "pred_val_nb = nbclassifier.predict(xvalid)\n",
    "nb_end_time = time.time()\n",
    "print(\"Total time spent on NB: {} seconds\".format(nb_end_time - nb_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "Precision:  0.7333333333333333\n",
      "Recall:  0.3697478991596639\n",
      "F1 Score:  0.4916201117318435\n",
      "MCC:  0.4090269641657418\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of Naive Bayes Classifier\n",
    "print(\"Naive Bayes\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_nb,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_nb,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_nb,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=1, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a Linear SVM (SGD) Classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_start_time = time.time()\n",
    "sgdclassifier = SGDClassifier(random_state = 1)\n",
    "sgdclassifier.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent on SVM (SGD): 0.7104437351226807 seconds\n"
     ]
    }
   ],
   "source": [
    "#Predicting on the validation set\n",
    "pred_val_sgd = sgdclassifier.predict(xvalid)\n",
    "sgd_end_time = time.time()\n",
    "print(\"Total time spent on SVM (SGD): {} seconds\".format(sgd_end_time - sgd_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM (SGD)\n",
      "Precision:  0.7886178861788617\n",
      "Recall:  0.8151260504201681\n",
      "F1 Score:  0.8016528925619835\n",
      "MCC:  0.722668539689978\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of Linear SVM (SGD) Classifier\n",
    "print(\"Linear SVM (SGD)\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Buidling a Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_start_time = time.time()\n",
    "rfc = RandomForestClassifier(random_state = 1)\n",
    "rfc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent on RFC: 3.885451555252075 seconds\n"
     ]
    }
   ],
   "source": [
    "#Predicting on the validation set\n",
    "pred_val_rfc = rfc.predict(xvalid)\n",
    "rfc_end_time = time.time()\n",
    "print(\"Total time spent on RFC: {} seconds\".format(rfc_end_time - rfc_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC\n",
      "Precision:  0.6496350364963503\n",
      "Recall:  0.7478991596638656\n",
      "F1 Score:  0.6953125\n",
      "MCC:  0.5673595005986476\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of Random Forest Classifier\n",
    "print(\"RFC\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_rfc,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_rfc,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_rfc,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Buidling a K Nearest Neighbours Classifer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc_start_time = time.time()\n",
    "knc = KNeighborsClassifier()\n",
    "knc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent on KNC: 8.525726556777954 seconds\n"
     ]
    }
   ],
   "source": [
    "#Predicting on the validation set\n",
    "pred_val_knc = knc.predict(xvalid)\n",
    "knc_end_time = time.time()\n",
    "print(\"Total time spent on KNC: {} seconds\".format(knc_end_time - knc_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNC\n",
      "Precision:  0.7\n",
      "Recall:  0.7058823529411765\n",
      "F1 Score:  0.7029288702928871\n",
      "MCC:  0.5863570989726369\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of K Nearest Neighbours Classifer\n",
    "print(\"KNC\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_knc,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_knc,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_knc,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_knc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessClassifier(copy_X_train=True, kernel=None,\n",
       "             max_iter_predict=100, multi_class='one_vs_rest', n_jobs=None,\n",
       "             n_restarts_optimizer=0, optimizer='fmin_l_bfgs_b',\n",
       "             random_state=1, warm_start=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Buidling a Gaussian Process Classifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "gpc_start_time = time.time()\n",
    "gpc = GaussianProcessClassifier(random_state = 1)\n",
    "gpc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent on GPC: 431.55591440200806 seconds\n"
     ]
    }
   ],
   "source": [
    "#Predicting on the validation set\n",
    "pred_val_gpc = gpc.predict(xvalid)\n",
    "gpc_end_time = time.time()\n",
    "print(\"Total time spent on GPC: {} seconds\".format(gpc_end_time - gpc_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPC\n",
      "Precision:  0.7545454545454545\n",
      "Recall:  0.6974789915966386\n",
      "F1 Score:  0.7248908296943231\n",
      "MCC:  0.6242334078185484\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of Gaussian Processs Classifier\n",
    "print(\"GPC\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_gpc,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_gpc,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_gpc,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_gpc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Buidling a Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc_start_time = time.time()\n",
    "dtc = DecisionTreeClassifier(random_state = 1)\n",
    "dtc.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent on GPC: 27.65597653388977 seconds\n"
     ]
    }
   ],
   "source": [
    "#Predicting on the validation set\n",
    "pred_val_dtc = dtc.predict(xvalid)\n",
    "dtc_end_time = time.time()\n",
    "print(\"Total time spent on GPC: {} seconds\".format(dtc_end_time - dtc_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC\n",
      "Precision:  0.49230769230769234\n",
      "Recall:  0.5378151260504201\n",
      "F1 Score:  0.5140562248995985\n",
      "MCC:  0.31322270106457617\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of Decision Tree Classifier\n",
    "print(\"DTC\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_dtc,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_dtc,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_dtc,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Buidling a MLP Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_start_time = time.time()\n",
    "mlp = MLPClassifier(random_state = 1)\n",
    "mlp.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent on MLP: 81.99546360969543 seconds\n"
     ]
    }
   ],
   "source": [
    "#Predicting on the validation set\n",
    "pred_val_mlp = mlp.predict(xvalid)\n",
    "mlp_end_time = time.time()\n",
    "print(\"Total time spent on MLP: {} seconds\".format(mlp_end_time - mlp_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n",
      "Precision:  0.7027027027027027\n",
      "Recall:  0.8739495798319328\n",
      "F1 Score:  0.7790262172284644\n",
      "MCC:  0.6878199687942644\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of MLP Classifier\n",
    "print(\"MLP\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_mlp,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_mlp,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_mlp,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Buidling a AdaBoost Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adab_start_time = time.time()\n",
    "adab = AdaBoostClassifier(random_state = 1)\n",
    "adab.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent on AdaBoost: 68.39412331581116 seconds\n"
     ]
    }
   ],
   "source": [
    "#Predicting on the validation set\n",
    "pred_val_adab = adab.predict(xvalid)\n",
    "adab_end_time = time.time()\n",
    "print(\"Total time spent on AdaBoost: {} seconds\".format(adab_end_time - adab_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "Precision:  0.6611570247933884\n",
      "Recall:  0.6722689075630253\n",
      "F1 Score:  0.6666666666666667\n",
      "MCC:  0.5351366082006004\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of AdaBoost Classifier\n",
    "print(\"AdaBoost\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_adab,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_adab,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_adab,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_adab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "               store_covariance=False, store_covariances=None, tol=0.0001)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Buidling a QDA Classifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda_start_time = time.time()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time spent on QDA: 3.2382919788360596 seconds\n"
     ]
    }
   ],
   "source": [
    "#Predicting on the validation set\n",
    "pred_val_qda = qda.predict(xvalid)\n",
    "qda_end_time = time.time()\n",
    "print(\"Total time spent on QDA: {} seconds\".format(qda_end_time - qda_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA\n",
      "Precision:  0.5163043478260869\n",
      "Recall:  0.7983193277310925\n",
      "F1 Score:  0.6270627062706271\n",
      "MCC:  0.4592002106490289\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of QDA Classifier\n",
    "print(\"QDA\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_qda,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_qda,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_qda,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_qda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(\"Total time of project execution: {} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i in ['hinge', 'log']:\n",
    "    for j in ['l2', 'elasticnet']:\n",
    "        for k in np.arange(0.0001,0.0010,0.0001):\n",
    "            sgd_start_time = time.time()\n",
    "            sgdclassifier = SGDClassifier(loss=i,penalty=j,alpha=k,random_state=1)\n",
    "            sgdclassifier.fit(xtrain,ytrain)\n",
    "            pred_val_sgd = sgdclassifier.predict(xvalid)\n",
    "            sgd_end_time = time.time()\n",
    "            print(\"Total time spent on SVM (SGD): {} seconds\".format(sgd_end_time - sgd_start_time))\n",
    "            print(\"Linear SVM (SGD) with \",i,j,k)\n",
    "            print(\"Precision: \",precision_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "            print(\"Recall: \",recall_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "            print(\"F1 Score: \",f1_score(yvalid, pred_val_sgd,pos_label='FAQ'))\n",
    "            print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_sgd))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_start_time = time.time()\n",
    "sgdclassifier = SGDClassifier(loss='hinge',penalty='elasticnet',max_iter=2000,random_state=1)\n",
    "sgdclassifier.fit(xtrain,ytrain)\n",
    "pred_val_sgd = sgdclassifier.predict(xvalid)\n",
    "sgd_end_time = time.time()\n",
    "print(\"Total time spent on SVM (SGD): {} seconds\".format(sgd_end_time - sgd_start_time))\n",
    "print(\"Linear SVM (SGD) with \",i,j,k)\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_sgd))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
